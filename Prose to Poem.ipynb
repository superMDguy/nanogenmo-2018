{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing\n",
    "from itertools import product\n",
    "import functools\n",
    "import operator\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import string\n",
    "import gensim\n",
    "from multiprocessing import Pool\n",
    "from random import choice\n",
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load('/mnt/bigfiles/dl/datasets/gensim-fasttext-300d-2M', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(phrase): return phrase.translate(str.maketrans({a:' ' for a in string.punctuation}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['steady',\n",
       " 'fast',\n",
       " 'slowed',\n",
       " 'rapid',\n",
       " 'slows',\n",
       " 'slowing',\n",
       " 'slower',\n",
       " 'slowness',\n",
       " 'slow',\n",
       " 'plodding',\n",
       " 'sluggish',\n",
       " 'slowest']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "INCLUDE_STOP = True\n",
    "def synonyms(word):\n",
    "    if not INCLUDE_STOP and word in stop:\n",
    "        return [word]\n",
    "    \n",
    "    most_similar = [word] + [data[0].lower().replace(' ', '-') for data in model.most_similar(positive=[word.lower()], topn=50)]\n",
    "    only_pronouncable = [word for word in most_similar if len(word) > 0 and len(pronouncing.phones_for_word(word)) > 0]\n",
    "    \n",
    "    return list(set(only_pronouncable))[:20]\n",
    "\n",
    "synonyms('slow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meter(line):\n",
    "    line = remove_punctuation(line) \n",
    "    syllables = 0 \n",
    "    stresses = []\n",
    "    for word in word_tokenize(line):\n",
    "        phonemes = pronouncing.phones_for_word(word)[0]\n",
    "        syllables += pronouncing.syllable_count(phonemes)\n",
    "        stresses.append(list(map(int, pronouncing.stresses(phonemes))))\n",
    "\n",
    "    return syllables, stresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, [[1], [1], [0, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_meter('that was amazing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_meter(line, meter, partial=False, start=0): # meter is an array with False for unstressed, True for stressed\n",
    "    line = remove_punctuation(line) \n",
    "    cycle_len = len(meter)\n",
    "    meter_step = start\n",
    "    \n",
    "    _, stresses = get_meter(line)\n",
    "    \n",
    "    for stress in stresses:\n",
    "        if len(stress) == 1:\n",
    "            meter_step += 1\n",
    "            continue # one syllable words can be stressed or not stressed\n",
    "        \n",
    "        for syllable in stress:\n",
    "            if syllable == 2:\n",
    "                meter_step += 1\n",
    "                continue # lightly stressed, can be either\n",
    "                \n",
    "            if (syllable == 1) == meter[meter_step % cycle_len]: \n",
    "                meter_step += 1\n",
    "                continue\n",
    "            else:\n",
    "                return False if not partial else (False, meter_step % cycle_len)\n",
    "            \n",
    "    if not partial:\n",
    "        if meter_step % cycle_len == 0: # end at the correct step\n",
    "            return True if not partial else (True, meter_step % cycle_len)\n",
    "        else:\n",
    "            return False if not partial else (False, meter_step % cycle_len)\n",
    "    else:\n",
    "        return True if not partial else (True, meter_step % cycle_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_start(line, meter):\n",
    "    for start in range(meter):\n",
    "        worked, state = check_meter(line, meter, partial=True, start=start)\n",
    "        if worked:\n",
    "            return start, state\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "iambic = [False, True]\n",
    "trochaic = [True, False]\n",
    "dactylic = [True, False, False]\n",
    "dactylic_hexameter = dactylic * 5 + [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(check_meter('How do I love thee? Let me count the ways.', iambic))\n",
    "print(check_meter('Is this smart enough to catch bad meter?', iambic))\n",
    "print(check_meter('Once upon a midnight dreary, while I pondered, weak and weary', trochaic))\n",
    "print(check_meter('This is the forest primeval, the murmuring pines and the hemlock', dactylic_hexameter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the ends of being and ideal grace.\n",
      "I love thee to the level of every day's\n"
     ]
    }
   ],
   "source": [
    "test_poem = \\\n",
    "'''How do I love thee? Let me count the ways.\n",
    "I love thee to the depth and breadth and height\n",
    "My soul can reach, when feeling out of sight\n",
    "For the ends of being and ideal grace.\n",
    "I love thee to the level of every day's\n",
    "Most quiet need, by sun and candle-light.\n",
    "I love thee freely, as men strive for right.\n",
    "I love thee purely, as they turn from praise.\n",
    "I love thee with the passion put to use\n",
    "In my old griefs, and with my childhood's faith.\n",
    "I love thee with a love I seemed to lose\n",
    "With my lost saints. I love thee with the breath,\n",
    "Smiles, tears, of all my life; and, if God choose,\n",
    "I shall but love thee better after death.\n",
    "'''.split('\\n')\n",
    "for line in test_poem:\n",
    "    try:\n",
    "        if not check_meter(line, iambic):\n",
    "            print(line)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/32074543/how-to-get-the-length-of-an-itertools-product\n",
    "def product_length(items): return functools.reduce(operator.mul, map(len, items), 1)\n",
    "\n",
    "def make_chunk_fit_meter(words, meter, start=0, return_early=10):\n",
    "    correct = []\n",
    "    word_synonyms = list(map(synonyms, words))\n",
    "                \n",
    "    for possible in product(*word_synonyms):\n",
    "        try:\n",
    "            result = check_meter(' '.join(possible), meter, start=start)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        if result:\n",
    "            correct.append(list(possible))\n",
    "\n",
    "            if return_early and len(correct) >= return_early:\n",
    "                break\n",
    "            \n",
    "    if len(correct) > 0:\n",
    "        return min(correct, key=lambda item: textstat.flesch_reading_ease(' '.join(item)))\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunk:\n",
    "    def __init__(self, start, end, correct):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.correct = correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n",
    "def partition(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "        \n",
    "CHUNK_MAX_WORDS = 12\n",
    "def clean_chunks(chunks):\n",
    "    cleaned = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        if chunk.correct == False and (chunk.end - chunk.start) >= CHUNK_MAX_WORDS:\n",
    "            chunklets = []\n",
    "            indices = partition(range(chunk.start, chunk.end), CHUNK_MAX_WORDS - 2)\n",
    "            for i in indices:\n",
    "                chunklets.append(Chunk(i[0], i[-1] + 1, False))\n",
    "            cleaned += chunklets\n",
    "        else:\n",
    "            cleaned.append(chunk)\n",
    "            \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_MIN_WORDS = 3\n",
    "\n",
    "def fit_meter(line, meter, return_early=10):\n",
    "    words = remove_punctuation(line).split(' ') # word_tokenize(line)\n",
    "    words = [word for word in words if len(word) is not 0]\n",
    "    try:\n",
    "        if check_meter(line, meter):\n",
    "            return [line]\n",
    "    except IndexError:\n",
    "        print('Some words not pronouncable')\n",
    "        return ''\n",
    "    \n",
    "    final = []\n",
    "    last_end = 0\n",
    "    while len(final) == 0 or last_end == len(words):\n",
    "        longest = None\n",
    "        start = 0\n",
    "        if len(final) > 0:\n",
    "            start = final[-1].end\n",
    "            \n",
    "        for i in range(start, len(words) - CHUNK_MIN_WORDS):\n",
    "            result = False\n",
    "\n",
    "            for j in range(i + CHUNK_MIN_WORDS, len(words) + 1):\n",
    "                chunk = words[i:j]\n",
    "                next_result, _ = check_meter(' '.join(chunk), meter, partial=True, start=0) # todo\n",
    "                \n",
    "                if next_result and not result:\n",
    "                    final.append(Chunk(last_end, i, False))\n",
    "                    \n",
    "                result = next_result\n",
    "\n",
    "                if result:\n",
    "                    longest = Chunk(i, j, True)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            if longest is not None:\n",
    "                final.append(longest)\n",
    "                last_end = longest.end\n",
    "                break\n",
    "            else:\n",
    "                print('ooops')\n",
    "                final.append(Chunk(i, len(words) - 1, False))\n",
    "                last_end = len(words) - 1\n",
    "                break\n",
    "                \n",
    "    if final[-1].end < len(words) - 1:\n",
    "        final.append(Chunk(final[-1].end, len(words), False))\n",
    "    \n",
    "    final = clean_chunks(final)\n",
    "                \n",
    "    sentence = []\n",
    "    meter_state = 0\n",
    "    for i, chunk in enumerate(tqdm(final)):\n",
    "        if chunk.start == chunk.end:\n",
    "            continue\n",
    "            \n",
    "        str_version = words[chunk.start:chunk.end]\n",
    "        \n",
    "        if chunk.correct:\n",
    "            sentence.append(' '.join(str_version))\n",
    "        else:\n",
    "            str_version = make_chunk_fit_meter(str_version, meter, start=meter_state, return_early=return_early)\n",
    "            if len(str_version) == 0:\n",
    "                print('Failed')\n",
    "                return ''\n",
    "            sentence.append(' '.join(str_version))\n",
    "            \n",
    "        result, meter_state = check_meter(' '.join(str_version), meter, start=meter_state, partial=True)\n",
    "        assert result\n",
    "           \n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418b3ae749f74f358dcc2635b911b1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the quick brown fox jumped up that lackadaisical rottweiler'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INCLUDE_STOP = True\n",
    "to_iambic = fit_meter(\"the quick brown fox jumped over the lazy dog\", dactylic, return_early=False)\n",
    "to_iambic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = '''\"Blessed are the poor in spirit, for theirs is the kingdom of heaven. Blessed are those who mourn, for they will be comforted. Blessed are the meek, for they will inherit the earth. Blessed are those who hunger and thirst for righteousness, for they will be filled.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_meter(' '.join(['the', 'massachusetts']), dactylic, start=0, partial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dactylic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dactylic = fit_meter(corpus, dactylic, return_early=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
