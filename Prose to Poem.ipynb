{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing\n",
    "from itertools import product\n",
    "import functools\n",
    "import operator\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import string\n",
    "import gensim\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load('/mnt/bigfiles/dl/datasets/gensim-fasttext-300d-2M', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(phrase): return phrase.translate(str.maketrans({a:None for a in string.punctuation}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['slow',\n",
       " 'slowing',\n",
       " 'sluggish',\n",
       " 'rapid',\n",
       " 'slowed',\n",
       " 'slower',\n",
       " 'fast',\n",
       " 'slows',\n",
       " 'steady',\n",
       " 'slowness',\n",
       " 'plodding',\n",
       " 'slowest']"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "INCLUDE_STOP = True\n",
    "def synonyms(word):\n",
    "    if not INCLUDE_STOP and word in stop:\n",
    "        return [word]\n",
    "    \n",
    "    most_similar = [word] + [data[0].lower() for data in model.most_similar(positive=[word.lower()], topn=50)]\n",
    "    only_pronouncable = [word for word in most_similar if len(pronouncing.phones_for_word(word)) > 0]\n",
    "    \n",
    "    return list(set(only_pronouncable))[:20]\n",
    "\n",
    "synonyms('slow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meter(line):\n",
    "    line = remove_punctuation(line) \n",
    "    syllables = 0 \n",
    "    stresses = []\n",
    "    for word in word_tokenize(line):\n",
    "        phonemes = pronouncing.phones_for_word(word)[0]\n",
    "        syllables += pronouncing.syllable_count(phonemes)\n",
    "        stresses.append(list(map(int, pronouncing.stresses(phonemes))))\n",
    "\n",
    "    return syllables, stresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, [[1], [1], [0, 1, 0]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_meter('that was amazing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_meter(line, meter, partial=False, start=0, n_syllables=None): # meter is an array with False for unstressed, True for stressed\n",
    "    line = remove_punctuation(line) \n",
    "    cycle_len = len(meter)\n",
    "    meter_step = start\n",
    "    \n",
    "    syllables, stresses = get_meter(line)\n",
    "    \n",
    "    if n_syllables and syllables is not n_syllables:\n",
    "        return False\n",
    "    \n",
    "    expected_next = False # not stressed\n",
    "    \n",
    "    for stress in stresses:\n",
    "        if len(stress) == 1:\n",
    "            meter_step += 1\n",
    "            continue # one syllable words can be stressed or not stressed\n",
    "        \n",
    "        for syllable in stress:\n",
    "            if syllable == 2:\n",
    "                meter_step += 1\n",
    "                continue # lightly stressed, can be either\n",
    "                \n",
    "            if (syllable == 1) == meter[meter_step % cycle_len]: \n",
    "                meter_step += 1\n",
    "                continue\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "    if not partial:\n",
    "        if meter_step % cycle_len == 0: # end at the correct step\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "iambic = [False, True]\n",
    "trochaic = [True, False]\n",
    "dactylic = [True, False, False]\n",
    "dactylic_hexameter = [True, False, False] * 5 + [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(check_meter('How do I love thee? Let me count the ways.', iambic))\n",
    "print(check_meter('Is this smart enough to catch bad meter?', iambic))\n",
    "print(check_meter('Once upon a midnight dreary, while I pondered, weak and weary', trochaic))\n",
    "print(check_meter('This is the forest primeval, the murmuring pines and the hemlock', dactylic_hexameter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the ends of being and ideal grace.\n",
      "I love thee to the level of every day's\n"
     ]
    }
   ],
   "source": [
    "test_poem = \\\n",
    "'''How do I love thee? Let me count the ways.\n",
    "I love thee to the depth and breadth and height\n",
    "My soul can reach, when feeling out of sight\n",
    "For the ends of being and ideal grace.\n",
    "I love thee to the level of every day's\n",
    "Most quiet need, by sun and candle-light.\n",
    "I love thee freely, as men strive for right.\n",
    "I love thee purely, as they turn from praise.\n",
    "I love thee with the passion put to use\n",
    "In my old griefs, and with my childhood's faith.\n",
    "I love thee with a love I seemed to lose\n",
    "With my lost saints. I love thee with the breath,\n",
    "Smiles, tears, of all my life; and, if God choose,\n",
    "I shall but love thee better after death.\n",
    "'''.split('\\n')\n",
    "for line in test_poem:\n",
    "    try:\n",
    "        if not check_meter(line, iambic):\n",
    "            print(line)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP\n",
    "def make_chunk_iambic(words):\n",
    "    word_synonyms = list(map(synonyms, words))\n",
    "    \n",
    "    iambic = []\n",
    "    # https://stackoverflow.com/questions/32074543/how-to-get-the-length-of-an-itertools-product\n",
    "    n_possible = functools.reduce(operator.mul, map(len, word_synonyms), 1)\n",
    "    for possible in tqdm(product(*word_synonyms), total=n_possible):\n",
    "        potential = ' '.join(possible)\n",
    "        try:\n",
    "            if check_iambic(potential):\n",
    "                return potential\n",
    "\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/32074543/how-to-get-the-length-of-an-itertools-product\n",
    "def product_length(items): return functools.reduce(operator.mul, map(len, word_synonyms), 1)\n",
    "\n",
    "def make_fit_meter(line, meter, return_early=10):\n",
    "    words = line.split(' ') # word_tokenize(line)\n",
    "    \n",
    "    correct = []\n",
    "    incorrect = []\n",
    "    for i in range(len(words)):\n",
    "        if check_meter(' '.join(words[:i + 1]), meter, partial=True):\n",
    "            correct = words[:i+1]\n",
    "        else:\n",
    "            incorrect = words[i:]\n",
    "            break\n",
    "            \n",
    "    word_synonyms = list(map(lambda word: [word], correct)) + list(map(synonyms, incorrect))\n",
    "            \n",
    "    for possible in tqdm(product(*word_synonyms), total=product_length(word_synonyms)):\n",
    "        potential = ' '.join(possible)\n",
    "        try:\n",
    "            if check_meter(potential, meter):\n",
    "                correct.append(potential)\n",
    "                print(potential)\n",
    "\n",
    "                if return_early and len(correct) >= return_early:\n",
    "                    return correct\n",
    "        except IndexError:\n",
    "            continue\n",
    "            \n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b877949b134c4c60ab1ba963f95c21df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INCLUDE_STOP = True\n",
    "to_iambic = make_fit_meter(\"The quick brown fox jumped over\", iambic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = word_tokenize(open('sermon_mount_NIV.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_iambic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
