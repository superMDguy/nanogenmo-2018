{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing\n",
    "from itertools import product\n",
    "import functools\n",
    "import operator\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import string\n",
    "import gensim\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load('/mnt/bigfiles/dl/datasets/gensim-fasttext-300d-2M', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(phrase): return phrase.translate(str.maketrans({a:None for a in string.punctuation}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['slow',\n",
       " 'slowing',\n",
       " 'sluggish',\n",
       " 'rapid',\n",
       " 'slowed',\n",
       " 'slower',\n",
       " 'fast',\n",
       " 'slows',\n",
       " 'steady',\n",
       " 'slowness',\n",
       " 'plodding',\n",
       " 'slowest']"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "INCLUDE_STOP = True\n",
    "def synonyms(word):\n",
    "    if not INCLUDE_STOP and word in stop:\n",
    "        return [word]\n",
    "    \n",
    "    most_similar = [word] + [data[0].lower() for data in model.most_similar(positive=[word.lower()], topn=50)]\n",
    "    only_pronouncable = [word for word in most_similar if len(pronouncing.phones_for_word(word)) > 0]\n",
    "    \n",
    "    return list(set(only_pronouncable))[:20]\n",
    "\n",
    "synonyms('slow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meter(line):\n",
    "    line = remove_punctuation(line) \n",
    "    syllables = 0 \n",
    "    stresses = []\n",
    "    for word in word_tokenize(line):\n",
    "        phonemes = pronouncing.phones_for_word(word)[0]\n",
    "        syllables += pronouncing.syllable_count(phonemes)\n",
    "        stresses.append(list(map(int, pronouncing.stresses(phonemes))))\n",
    "\n",
    "    return syllables, stresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, [[1], [1], [0, 1, 0]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_meter('that was amazing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_meter(line, meter, partial=False, start=0): # meter is an array with False for unstressed, True for stressed\n",
    "    line = remove_punctuation(line) \n",
    "    cycle_len = len(meter)\n",
    "    meter_step = start\n",
    "    \n",
    "    _, stresses = get_meter(line)\n",
    "    \n",
    "    for stress in stresses:\n",
    "        if len(stress) == 1:\n",
    "            meter_step += 1\n",
    "            continue # one syllable words can be stressed or not stressed\n",
    "        \n",
    "        for syllable in stress:\n",
    "            if syllable == 2:\n",
    "                meter_step += 1\n",
    "                continue # lightly stressed, can be either\n",
    "                \n",
    "            if (syllable == 1) == meter[meter_step % cycle_len]: \n",
    "                meter_step += 1\n",
    "                continue\n",
    "            else:\n",
    "                return False if not partial else (False, meter_step % cycle_len)\n",
    "            \n",
    "    if not partial:\n",
    "        if meter_step % cycle_len == 0: # end at the correct step\n",
    "            return True if not partial else (True, meter_step % cycle_len)\n",
    "        else:\n",
    "            return False if not partial else (False, meter_step % cycle_len)\n",
    "    else:\n",
    "        return True if not partial else (True, meter_step % cycle_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "iambic = [False, True]\n",
    "trochaic = [True, False]\n",
    "dactylic = [True, False, False]\n",
    "dactylic_hexameter = [True, False, False] * 5 + [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(check_meter('How do I love thee? Let me count the ways.', iambic))\n",
    "print(check_meter('Is this smart enough to catch bad meter?', iambic))\n",
    "print(check_meter('Once upon a midnight dreary, while I pondered, weak and weary', trochaic))\n",
    "print(check_meter('This is the forest primeval, the murmuring pines and the hemlock', dactylic_hexameter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the ends of being and ideal grace.\n",
      "I love thee to the level of every day's\n"
     ]
    }
   ],
   "source": [
    "test_poem = \\\n",
    "'''How do I love thee? Let me count the ways.\n",
    "I love thee to the depth and breadth and height\n",
    "My soul can reach, when feeling out of sight\n",
    "For the ends of being and ideal grace.\n",
    "I love thee to the level of every day's\n",
    "Most quiet need, by sun and candle-light.\n",
    "I love thee freely, as men strive for right.\n",
    "I love thee purely, as they turn from praise.\n",
    "I love thee with the passion put to use\n",
    "In my old griefs, and with my childhood's faith.\n",
    "I love thee with a love I seemed to lose\n",
    "With my lost saints. I love thee with the breath,\n",
    "Smiles, tears, of all my life; and, if God choose,\n",
    "I shall but love thee better after death.\n",
    "'''.split('\\n')\n",
    "for line in test_poem:\n",
    "    try:\n",
    "        if not check_meter(line, iambic):\n",
    "            print(line)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/32074543/how-to-get-the-length-of-an-itertools-product\n",
    "def product_length(items): return functools.reduce(operator.mul, map(len, items), 1)\n",
    "\n",
    "# WIP\n",
    "def make_chunk_fit_meter(words, meter, start=0, return_early=10):\n",
    "    correct = []\n",
    "    word_synonyms = list(map(synonyms, words))\n",
    "                \n",
    "    for possible in tqdm(product(*word_synonyms), total=product_length(word_synonyms)):\n",
    "        potential = ' '.join(possible)\n",
    "        try:\n",
    "            if check_meter(potential, meter, start=start):\n",
    "                correct.append(potential)\n",
    "#                 print(potential)\n",
    "\n",
    "                if return_early and len(correct) >= return_early:\n",
    "                    return correct\n",
    "        except IndexError:\n",
    "            continue\n",
    "            \n",
    "#     print(correct)\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunk:\n",
    "    def __init__(self, start, end, meter_state, correct):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.meter_state = meter_state\n",
    "        self.correct = correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_MIN_WORDS = 3\n",
    "\n",
    "def fit_meter(line, meter, return_early=10):\n",
    "    words = line.split(' ') # word_tokenize(line)\n",
    "    try:\n",
    "        if check_meter(line, meter):\n",
    "            return [line]\n",
    "    except IndexError:\n",
    "        print('Some words not pronouncable')\n",
    "        return []\n",
    "    \n",
    "    final = []\n",
    "    last_end = 0\n",
    "    while len(final) == 0 or last_end == len(words):\n",
    "        longest = None\n",
    "        start = 0\n",
    "        if len(final) > 0:\n",
    "            start = final[-1].end\n",
    "            \n",
    "        for i in range(start, len(words) - CHUNK_MIN_WORDS):\n",
    "            result = False\n",
    "            last_continue = 0\n",
    "\n",
    "            for j in range(i + CHUNK_MIN_WORDS, len(words) + 1):\n",
    "                chunk = words[i:j]\n",
    "                next_result, continuePoint = check_meter(' '.join(chunk), meter, partial=True, start=last_continue)\n",
    "                \n",
    "                if not result and next_result:\n",
    "                    final.append(Chunk(last_end, i, None, False))\n",
    "                result = next_result\n",
    "\n",
    "                if result:\n",
    "                    last_continue = continuePoint\n",
    "                    longest = Chunk(i, j, continuePoint, True)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            if longest is not None:\n",
    "                final.append(longest)\n",
    "                last_end = longest.end\n",
    "                break\n",
    "                \n",
    "    if final[-1].end < len(words) - 1:\n",
    "        final.append(Chunk(final[-1].end, len(words), None, False))\n",
    "                \n",
    "    possibilities = []\n",
    "    for item in final:\n",
    "        print(words[item.start:item.end])\n",
    "#     possibilities = [[' '.join(correct)]] \n",
    "#     if len(incorrect) > 0:\n",
    "#         possibilities.append(make_chunk_fit_meter(incorrect, meter, start=continuePoint, return_early=return_early))\n",
    "           \n",
    "#     return possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disgusting']\n",
      "['the', 'quick', 'brown', 'fox', 'jumped']\n",
      "['over', 'the', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "INCLUDE_STOP = True\n",
    "to_iambic = fit_meter(\"disgusting the quick brown fox jumped over the lazy dog\", dactylic)\n",
    "to_iambic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = word_tokenize(open('sermon_mount_NIV.txt').read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
