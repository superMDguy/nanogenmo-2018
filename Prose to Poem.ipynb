{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet \n",
    "import pronouncing\n",
    "from itertools import product\n",
    "import functools\n",
    "import operator\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slow',\n",
       " 'decelerate',\n",
       " 'slow',\n",
       " 'slow_down',\n",
       " 'slow_up',\n",
       " 'retard',\n",
       " 'slow',\n",
       " 'slow_down',\n",
       " 'slow_up',\n",
       " 'slack',\n",
       " 'slacken',\n",
       " 'slow',\n",
       " 'slow_down',\n",
       " 'slow_up',\n",
       " 'slow',\n",
       " 'slow',\n",
       " 'dense',\n",
       " 'dim',\n",
       " 'dull',\n",
       " 'dumb',\n",
       " 'obtuse',\n",
       " 'slow',\n",
       " 'slow',\n",
       " 'boring',\n",
       " 'deadening',\n",
       " 'dull',\n",
       " 'ho-hum',\n",
       " 'irksome',\n",
       " 'slow',\n",
       " 'tedious',\n",
       " 'tiresome',\n",
       " 'wearisome',\n",
       " 'dull',\n",
       " 'slow',\n",
       " 'sluggish',\n",
       " 'slowly',\n",
       " 'slow',\n",
       " 'easy',\n",
       " 'tardily',\n",
       " 'behind',\n",
       " 'slow']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "INCLUDE_STOP = True\n",
    "# https://www.geeksforgeeks.org/get-synonymsantonyms-nltk-wordnet-python/\n",
    "def synonyms(word):\n",
    "    synonyms = [word]\n",
    "    \n",
    "    if not INCLUDE_STOP and word in stop:\n",
    "        return synonyms\n",
    "    \n",
    "    for syn in wordnet.synsets(word): \n",
    "        for l in syn.lemmas(): \n",
    "            synonyms.append(l.name()) \n",
    "                \n",
    "    return synonyms\n",
    "\n",
    "synonyms('slow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meter(phrase):\n",
    "    phrase = phrase.translate(str.maketrans({a:None for a in string.punctuation})) # strip punctuation\n",
    "    syllables = 0 \n",
    "    stresses = []\n",
    "    for word in word_tokenize(phrase):\n",
    "#         try:\n",
    "        phonemes = pronouncing.phones_for_word(word)[0]\n",
    "        syllables += pronouncing.syllable_count(phonemes)\n",
    "        stresses.append(list(map(int, pronouncing.stresses(phonemes))))\n",
    "#         except IndexError:\n",
    "# #             print(f'\\tError: word without phoneme found: \"{word}\"')\n",
    "#             syllables += 1\n",
    "#             stresses.append([1])\n",
    "\n",
    "    return (syllables, stresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, [[1], [1], [0, 1, 0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meter('that was amazing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_iambic(line):\n",
    "    syllables, stresses = meter(line)\n",
    "    \n",
    "    if syllables is not 10:\n",
    "        return False\n",
    "    \n",
    "    expected_next = False # not stressed\n",
    "    \n",
    "    for stress in stresses:\n",
    "        if len(stress) == 1:\n",
    "            expected_next = not expected_next\n",
    "            continue # one syllable can be stressed or not stressed\n",
    "        \n",
    "        for syllable in stress:\n",
    "            if syllable == 2:\n",
    "                expected_next = not expected_next\n",
    "                continue # lightly stressed, can be either\n",
    "                \n",
    "            if (syllable == 1) == expected_next:\n",
    "                expected_next = not expected_next\n",
    "                continue\n",
    "            else:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(check_iambic('How do I love thee? Let me count the ways.'))\n",
    "print(check_iambic('Is this smarter than simply syllables?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the ends of being and ideal grace.\n",
      "I love thee to the level of every day's\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_poem = \\\n",
    "'''How do I love thee? Let me count the ways.\n",
    "I love thee to the depth and breadth and height\n",
    "My soul can reach, when feeling out of sight\n",
    "For the ends of being and ideal grace.\n",
    "I love thee to the level of every day's\n",
    "Most quiet need, by sun and candle-light.\n",
    "I love thee freely, as men strive for right.\n",
    "I love thee purely, as they turn from praise.\n",
    "I love thee with the passion put to use\n",
    "In my old griefs, and with my childhood's faith.\n",
    "I love thee with a love I seemed to lose\n",
    "With my lost saints. I love thee with the breath,\n",
    "Smiles, tears, of all my life; and, if God choose,\n",
    "I shall but love thee better after death.\n",
    "'''.split('\\n')\n",
    "for line in test_poem:\n",
    "    try:\n",
    "        if not check_iambic(line):\n",
    "            print(line)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_iambic(line):\n",
    "    words = line.split(' ') # word_tokenize(line)\n",
    "    word_synonyms = list(map(synonyms, words))\n",
    "    \n",
    "    for i, syns in enumerate(word_synonyms):\n",
    "        if len(syns) == 0:\n",
    "            word_synonyms[i] = [words[i]]\n",
    "            \n",
    "    iambic = []\n",
    "    # https://stackoverflow.com/questions/32074543/how-to-get-the-length-of-an-itertools-product\n",
    "    n_possible = functools.reduce(operator.mul, map(len, word_synonyms), 1)\n",
    "    for possible in tqdm(product(*word_synonyms), total=n_possible):\n",
    "        potential = ' '.join(possible)\n",
    "        try:\n",
    "            if check_iambic(potential):\n",
    "                iambic.append(potential)\n",
    "        except IndexError: # can't find pronunciation\n",
    "            continue\n",
    "    return iambic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcd4ebc5add44d9a129e7309ad2b6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15210), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['For the ends of existence and saint grace.',\n",
       " 'For the ends of embody and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.',\n",
       " 'For the last of existence and saint grace.',\n",
       " 'For the last of embody and saint grace.',\n",
       " 'For the goal of existence and saint grace.',\n",
       " 'For the goal of embody and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.',\n",
       " 'For the destruction of be and saint grace.',\n",
       " 'For the destruction of be and saint grace.',\n",
       " 'For the destruction of be and saint grace.',\n",
       " 'For the destruction of be and saint grace.',\n",
       " 'For the destruction of be and saint grace.',\n",
       " 'For the destruction of be and saint grace.',\n",
       " 'For the destruction of be and saint grace.',\n",
       " 'For the destruction of be and saint grace.',\n",
       " 'For the destruction of be and saint grace.',\n",
       " 'For the destruction of be and saint grace.',\n",
       " 'For the destruction of be and saint grace.',\n",
       " 'For the destruction of live and saint grace.',\n",
       " 'For the destruction of be and saint grace.',\n",
       " 'For the destruction of cost and saint grace.',\n",
       " 'For the destruction of be and saint grace.',\n",
       " 'For the death of existence and saint grace.',\n",
       " 'For the death of embody and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.',\n",
       " 'For the conclusion of be and saint grace.',\n",
       " 'For the conclusion of be and saint grace.',\n",
       " 'For the conclusion of be and saint grace.',\n",
       " 'For the conclusion of be and saint grace.',\n",
       " 'For the conclusion of be and saint grace.',\n",
       " 'For the conclusion of be and saint grace.',\n",
       " 'For the conclusion of be and saint grace.',\n",
       " 'For the conclusion of be and saint grace.',\n",
       " 'For the conclusion of be and saint grace.',\n",
       " 'For the conclusion of be and saint grace.',\n",
       " 'For the conclusion of be and saint grace.',\n",
       " 'For the conclusion of live and saint grace.',\n",
       " 'For the conclusion of be and saint grace.',\n",
       " 'For the conclusion of cost and saint grace.',\n",
       " 'For the conclusion of be and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.',\n",
       " 'For the close of existence and saint grace.',\n",
       " 'For the close of embody and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.',\n",
       " 'For the remainder of be and saint grace.',\n",
       " 'For the remainder of be and saint grace.',\n",
       " 'For the remainder of be and saint grace.',\n",
       " 'For the remainder of be and saint grace.',\n",
       " 'For the remainder of be and saint grace.',\n",
       " 'For the remainder of be and saint grace.',\n",
       " 'For the remainder of be and saint grace.',\n",
       " 'For the remainder of be and saint grace.',\n",
       " 'For the remainder of be and saint grace.',\n",
       " 'For the remainder of be and saint grace.',\n",
       " 'For the remainder of be and saint grace.',\n",
       " 'For the remainder of live and saint grace.',\n",
       " 'For the remainder of be and saint grace.',\n",
       " 'For the remainder of cost and saint grace.',\n",
       " 'For the remainder of be and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.',\n",
       " 'For the stop of existence and saint grace.',\n",
       " 'For the stop of embody and saint grace.',\n",
       " 'For the cease of existence and saint grace.',\n",
       " 'For the cease of embody and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.',\n",
       " 'For the end of existence and saint grace.',\n",
       " 'For the end of embody and saint grace.']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INCLUDE_STOP = True\n",
    "make_iambic('For the ends of being and ideal grace.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = word_tokenize(open('sermon_mount_NIV.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_iambic(corpus):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
