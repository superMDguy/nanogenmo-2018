{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing\n",
    "from itertools import product\n",
    "import functools\n",
    "import operator\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import string\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('InferSent/dataset/fastText/crawl-300d-2M.vec')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(phrase): return phrase.translate(str.maketrans({a:None for a in string.punctuation}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['slows',\n",
       " 'sluggish',\n",
       " 'slowest',\n",
       " 'slowness',\n",
       " 'slowing',\n",
       " 'rapid',\n",
       " 'slowed',\n",
       " 'steady',\n",
       " 'slow',\n",
       " 'plodding',\n",
       " 'fast',\n",
       " 'slower']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "INCLUDE_STOP = True\n",
    "def synonyms(word):\n",
    "    if not INCLUDE_STOP and word in stop:\n",
    "        return [word]\n",
    "    \n",
    "    most_similar =model.most_similar(positive=[word], topn=50)\n",
    "    \n",
    "    return list(set([word[0].lower() for word in most_similar if len(pronouncing.phones_for_word(word[0])) > 0]))[:50]\n",
    "\n",
    "synonyms('slow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meter(phrase):\n",
    "    phrase = remove_punctuation(phrase) \n",
    "    syllables = 0 \n",
    "    stresses = []\n",
    "    for word in word_tokenize(phrase):\n",
    "        phonemes = pronouncing.phones_for_word(word)[0]\n",
    "        syllables += pronouncing.syllable_count(phonemes)\n",
    "        stresses.append(list(map(int, pronouncing.stresses(phonemes))))\n",
    "\n",
    "    return syllables, stresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, [[1], [1], [0, 1, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_meter('that was amazing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_meter(line, meter, n_syllables=None): # meter is an array with False for unstressed, True for stressed\n",
    "    cycle_len = len(meter)\n",
    "    meter_step = 0\n",
    "    \n",
    "    syllables, stresses = get_meter(line)\n",
    "    \n",
    "    if n_syllables and syllables is not n_syllables:\n",
    "        return False\n",
    "    \n",
    "    expected_next = False # not stressed\n",
    "    \n",
    "    for stress in stresses:\n",
    "        if len(stress) == 1:\n",
    "            meter_step += 1\n",
    "            continue # one syllable can be stressed or not stressed\n",
    "        \n",
    "        for syllable in stress:\n",
    "            if syllable == 2:\n",
    "                meter_step += 1\n",
    "                continue # lightly stressed, can be either\n",
    "                \n",
    "            if (syllable == 1) == meter[meter_step % cycle_len]: \n",
    "                meter_step += 1\n",
    "                continue\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "    if meter_step % cycle_len == 0: # end at the correct step\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_iambic(line):\n",
    "    return check_meter(line, [False, True])\n",
    "\n",
    "def check_trochaic(line):\n",
    "    return check_meter(line, [True, False])\n",
    "\n",
    "def check_dactylic_hexameter(line):\n",
    "    return check_meter(line, [True, False, False] * 5 + [True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(check_iambic('How do I love thee? Let me count the ways.'))\n",
    "print(check_iambic('Is this smart enough to catch bad meter?'))\n",
    "\n",
    "print(check_dactylic_hexameter('This is the forest primeval, the murmuring pines and the hemlock'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the ends of being and ideal grace.\n",
      "I love thee to the level of every day's\n"
     ]
    }
   ],
   "source": [
    "test_poem = \\\n",
    "'''How do I love thee? Let me count the ways.\n",
    "I love thee to the depth and breadth and height\n",
    "My soul can reach, when feeling out of sight\n",
    "For the ends of being and ideal grace.\n",
    "I love thee to the level of every day's\n",
    "Most quiet need, by sun and candle-light.\n",
    "I love thee freely, as men strive for right.\n",
    "I love thee purely, as they turn from praise.\n",
    "I love thee with the passion put to use\n",
    "In my old griefs, and with my childhood's faith.\n",
    "I love thee with a love I seemed to lose\n",
    "With my lost saints. I love thee with the breath,\n",
    "Smiles, tears, of all my life; and, if God choose,\n",
    "I shall but love thee better after death.\n",
    "'''.split('\\n')\n",
    "for line in test_poem:\n",
    "    try:\n",
    "        if not check_iambic(line):\n",
    "            print(line)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP\n",
    "def make_chunk_iambic(words):\n",
    "    word_synonyms = list(map(synonyms, words))\n",
    "    \n",
    "    iambic = []\n",
    "    # https://stackoverflow.com/questions/32074543/how-to-get-the-length-of-an-itertools-product\n",
    "    n_possible = functools.reduce(operator.mul, map(len, word_synonyms), 1)\n",
    "    for possible in tqdm(product(*word_synonyms), total=n_possible):\n",
    "        potential = ' '.join(possible)\n",
    "        try:\n",
    "            if check_iambic(potential):\n",
    "                return potential\n",
    "\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_iambic(line, return_early=10):\n",
    "    words = line.split(' ') # word_tokenize(line)\n",
    "    word_synonyms = list(map(synonyms, words))\n",
    "    \n",
    "    for i, syns in enumerate(word_synonyms):\n",
    "        if len(syns) == 0:\n",
    "            word_synonyms[i] = [words[i]]\n",
    "            \n",
    "    iambic = []\n",
    "    # https://stackoverflow.com/questions/32074543/how-to-get-the-length-of-an-itertools-product\n",
    "    n_possible = functools.reduce(operator.mul, map(len, word_synonyms), 1)\n",
    "    for possible in tqdm(product(*word_synonyms), total=n_possible):\n",
    "        potential = ' '.join(possible)\n",
    "        if check_iambic(potential):\n",
    "            iambic.append(potential)\n",
    "            \n",
    "            if return_early and len(iambic) >= return_early:\n",
    "                return iambic\n",
    "    return iambic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: some words have unknown pronunciation\n",
      "Getting synonyms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a077cee7b76d47bc9d76cd87adc89fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INCLUDE_STOP = False\n",
    "iambic = make_iambic(\"hot sauce contained in a nice tin can may be a little weird\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = word_tokenize(open('sermon_mount_NIV.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_iambic(corpus):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0, 0, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
