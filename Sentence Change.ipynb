{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from InferSent.models import InferSent\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from random import choice\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from annoy import AnnoyIndex\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load `InferSent` Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'InferSent/encoder/infersent2.pkl'\n",
    "params = {'bsize': 256, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "            'pool_type': 'max', 'dpout_model': 0.0, 'version': 2}\n",
    "model = InferSent(params).cuda()\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V_PATH = 'InferSent/dataset/fastText/crawl-300d-2M.vec'\n",
    "model.set_w2v_path(W2V_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '/mnt/bigfiles/dl/datasets/Gutenberg/'\n",
    "books = os.listdir(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(author):\n",
    "    corpus = ''\n",
    "    \n",
    "    for book in books:\n",
    "        if f'{author}__' in book:\n",
    "            corpus += open(prefix + book).read() + '\\n\\n'\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEWLINE = '<NEWLINE>'\n",
    "def tokenize_sentences(text):\n",
    "    open('/tmp/in.txt', 'w').write(text.replace('\\n\\n', NEWLINE))\n",
    "    os.system('/mnt/bigfiles/dl/datasets/stanford-parser-full-2017-06-09/tokenize_sent.sh')\n",
    "    tokens = open('/tmp/out.txt').read().split('\\n')\n",
    "    print('Total tokens in dataset', len(tokens))\n",
    "\n",
    "    return [token for token in tokens if len(token) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize_sentences(sentences):\n",
    "    open('/tmp/in.txt', 'w').write(' '.join(sentences).replace(NEWLINE, '\\n\\n'))\n",
    "    os.system('/mnt/bigfiles/dl/datasets/stanford-parser-full-2017-06-09/detokenize.sh')\n",
    "    \n",
    "    return open('/tmp/out.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_book(toChange, source, withTranslation = True, useAnnoy = False, maxChars = 5000000):\n",
    "    toChangeSent = tokenize_sentences(toChange)\n",
    "    sourceSent = tokenize_sentences(source[:maxChars])\n",
    "    \n",
    "    model.build_vocab(toChangeSent + sourceSent, tokenize=True)\n",
    "    \n",
    "    toChangeVecs = model.encode(toChangeSent, tokenize=True)\n",
    "    sourceVecs = model.encode(sourceSent, tokenize=True)\n",
    "    \n",
    "    changed = []\n",
    "    \n",
    "    if useAnnoy:\n",
    "        print('Building index...')\n",
    "        index = AnnoyIndex(len(sourceVecs[0]), metric='dot')\n",
    "        for (i, vec) in enumerate(sourceVecs):\n",
    "            index.add_item(i, vec)\n",
    "        index.build(25)\n",
    "\n",
    "        for lineVec in tqdm(toChangeVecs):\n",
    "            closestIdx = index.get_nns_by_vector(lineVec, 1)[0]\n",
    "            changed.append(sourceSent[closestIdx])\n",
    "    else:\n",
    "        print('Computing pairwise cosine distances...')\n",
    "        distances = pairwise_distances(toChangeVecs, sourceVecs, metric='cosine', n_jobs=-1)\n",
    "        \n",
    "        for i in tqdm(range(len(toChangeVecs))):\n",
    "            if withTranslation:\n",
    "                changed.append(toChangeSent[i])\n",
    " \n",
    "            sentence_distances = np.array([distances[i, j] for j in range(len(sourceVecs))])\n",
    "            closestIdx = np.argmin(sentence_distances)\n",
    "            changed.append(sourceSent[closestIdx])\n",
    "            \n",
    "           \n",
    "    \n",
    "    if withTranslation:\n",
    "        out = ''\n",
    "        punctuationRe = re.compile(r' ([\\.,!\\?;:])')\n",
    "        for i, line in enumerate(changed):\n",
    "            cleaned = punctuationRe.sub(r'\\1', line.replace(NEWLINE, '')).replace('\\n', '').replace('-LRB- ', ' (').replace('-RRB-', ')')\n",
    "\n",
    "            if i % 2 == 0:\n",
    "                out += f'_{cleaned.strip()}_<br/>'\n",
    "            else:\n",
    "                out += f'{cleaned}\\n\\n'\n",
    "        return out\n",
    "    else:\n",
    "        return detokenize_sentences(changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(name, title, changed, withTranslation=True):\n",
    "    header = ''\n",
    "    \n",
    "    if withTranslation:\n",
    "        header = f'# {title}\\n' \n",
    "        header += '## Matthew Dangerfield\\n'\n",
    "        header += '_NaNoGenMo, 2018_\\n<br/>'\n",
    "        header += '**Original text is in italics, followed by the translated version**\\n\\n'\n",
    "        open(f'{name}.md', 'w').write(header + changed)\n",
    "    else:\n",
    "        header = f'% {title}\\n' + \\\n",
    "        '% Matthew Dangerfield\\n' + \\\n",
    "        '% NaNoGenMo, 2018\\n'\n",
    "        \n",
    "        open('/tmp/out.txt', 'w').write(header + changed)\n",
    "        os.system(f'pandoc /tmp/out.txt -o {name}.pdf')\n",
    "    print('Words: ', len(changed.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in dataset 3615\n",
      "Total tokens in dataset 54092\n",
      "Found 32402(/35548) words with w2v vectors\n",
      "Vocab size : 32402\n",
      "Computing pairwise cosine distances...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304916e5fc6645ce92a35b52a509969e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3614), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Words:  187866\n"
     ]
    }
   ],
   "source": [
    "changed = change_book(open(prefix + 'Jane Austen___Northanger Abbey.txt').read(), get_corpus('Sir Arthur Conan Doyle'))\n",
    "write_file('Northanger_Abbey_x_Doyle_with_translation', \"Sir Arthur Conan Doyle's Northanger Abbey\", changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in dataset 3615\n",
      "Total tokens in dataset 54092\n",
      "Found 32402(/35548) words with w2v vectors\n",
      "Vocab size : 32402\n",
      "Computing pairwise cosine distances...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7898dad40f2c442a9edf1790e842b104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3614), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Words:  110828\n"
     ]
    }
   ],
   "source": [
    "changed = change_book(open(prefix + 'Jane Austen___Northanger Abbey.txt').read(), get_corpus('Sir Arthur Conan Doyle'), withTranslation=False)\n",
    "write_file('Northanger_Abbey_x_Doyle', \"Sir Arthur Conan Doyle's Northanger Abbey\", changed, withTranslation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample:\n",
      " \n",
      "\n",
      " A celebrated Psychic, Mrs. Piper, uttered, in the year 1899 words which were recorded by Dr. Hodgson at the time. This I concealed where no one has ever discovered it; but my fears would not allow me to go back for the other, as I might perhaps have done, had I foreseen how terribly its presence might tell against my master. Still, I could not see what harm could come to me by complying with his request, and certainly I could not have devised any arrangement which would give me such an opportunity of satisfying my curiosity. It was indeed this attitude upon the part of my friend and certainly not any lack of interesting material which has caused me of late years to lay very few of my records before the public. These treats were, however, rare events, and made such a mark upon my mind, that when I was sixteen years of age I could have checked off upon my fingers all that I had ever seen. \n",
      "\n",
      " Everything which the girl said seemed to be meant as an insult to me, and yet I could not imagine how I had ever offended her. Her whole life was a round of devotion and of love, which was divided between her husband and her only son, Harold. \"You must know, Sir Charles, that though my son knew nothing of his parents, we were both alive, and had never lost sight of him. Now that they had not only ceased to protect him, but had themselves become a source of trouble to him, he began to understand how great the blessing was which he had enjoyed, and to sigh for the happy days before his girls had come under the influence of his neighbor. In her pure and earnest mind her mother's memory was enshrined as that of a saint, and the thought that any one should take her place seemed a terrible desecration. He was married to the second daughter of Sir James Ovington; and as I have seen three of his grandchildren within the week, I fancy that if any of Sir Lothian's descendants have their eye upon the property, they are likely to be as disappointed as their ancestor was before them. \n",
      "\n",
      " \"I have already explained to our young friend here,\" said Challenger (he has a way of alluding to me as if I were a school child ten years old), \"that it is quite impossible that there should be an easy way up anywhere, for the simple reason that if there were the summit would not be isolated, and those conditions would not obtain which have effected so singular an interference with the general laws of survival. Her face had neither regularity of feature nor beauty of complexion, but her expression was sweet and amiable, and her large blue eyes were singularly spiritual and sympathetic. \n",
      "\n",
      " \n",
      "\n",
      " SHAKESPEARE'S EXPOSTULATION -LSB- 101 -RSB- \n",
      "\n",
      " Masters, I sleep not quiet in my grave, There where they laid me, by the Avon shore, In that some crazy wights have set it forth By arguments most false and fanciful, Analogy and far-drawn inference, That Francis Bacon, Earl of Verulam (A man whom I remember in old days, A learned judge with sly adhesive palms, To which the suitor's gold was wont to stic\n"
     ]
    }
   ],
   "source": [
    "print('Sample:\\n', changed[:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bible x Quran Experiment\n",
    "No offense intended to anyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-11-06 22:28:40--  https://www.clearquran.com/downloads/quran-verse-by-verse-text.zip\n",
      "Resolving www.clearquran.com (www.clearquran.com)... 104.24.8.47, 104.24.9.47\n",
      "Connecting to www.clearquran.com (www.clearquran.com)|104.24.8.47|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1198126 (1.1M) [application/zip]\n",
      "Saving to: ‘quran.zip’\n",
      "\n",
      "quran.zip           100%[===================>]   1.14M   545KB/s    in 2.1s    \n",
      "\n",
      "2018-11-06 22:28:42 (545 KB/s) - ‘quran.zip’ saved [1198126/1198126]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./fetch_quran.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "quran = open('quran.txt').read()\n",
    "sermon_mount = open('sermon_mount_NIV.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in dataset 140\n",
      "Total tokens in dataset 11004\n",
      "Found 7218(/7271) words with w2v vectors\n",
      "Vocab size : 7218\n",
      "Computing pairwise cosine distances...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad89b46ab6a45988a11666f18358fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=139), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Words:  5506\n"
     ]
    }
   ],
   "source": [
    "changed = change_book(sermon_mount, quran).replace('`` ', '\"')\n",
    "write_file('sermon_mount_x_quran', \"The Sermon on the Mount, Quran Crossover Edition\", changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
